{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "broadband-wyoming"
      },
      "source": [
        "# HCP Retinotopy Data Loader\n",
        "\n",
        "The HCP 7T retinotopyy dataset comprises fMRI retinotopy from 183 human subjects. The NMA-curated dataset includes the average data over all those subjects.\n",
        "\n",
        "In order to use this dataset, please electronically sign the HCP data use terms at [ConnectomeDB](https://db.humanconnectome.org). Instructions for this are on pp. 24-25 of the [HCP Reference Manual](https://www.humanconnectome.org/storage/app/media/documentation/s1200/HCP_S1200_Release_Reference_Manual.pdf).\n",
        "\n",
        "The data and experiment are decribed in detail in [Benson et al.](https://jov.arvojournals.org/article.aspx?articleid=2719988#207329261)"
      ],
      "id": "broadband-wyoming"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vLO3y0YR7Sv"
      },
      "outputs": [],
      "source": [
        "#!pip install nilearn --quiet\n",
        "#!pip install nltools --quiet\n",
        "#!pip install git+https://github.com/VU-Cog-Sci/nideconv --quiet\n",
        "!pip install matplotlib==3.3.0"
      ],
      "id": "7vLO3y0YR7Sv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asian-munich"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from nilearn import plotting\n",
        "from scipy.stats import gamma\n",
        "from matplotlib import animation\n",
        "from nltools.data import Design_Matrix"
      ],
      "id": "asian-munich"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSdEhS5jKzkb"
      },
      "source": [
        "# Basic parameters"
      ],
      "id": "CSdEhS5jKzkb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I7CVWshKz9yC"
      },
      "outputs": [],
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "DATA_DIR = \"./hcp_retino\"\n",
        "if not os.path.isdir(DATA_DIR):\n",
        "  os.mkdir(DATA_DIR)\n",
        "\n",
        "# The data acquisition rate\n",
        "TR = 1  # Time resolution, in sec\n",
        "\n",
        "# Time series data are organized by experiment, with each experiment\n",
        "# having an LR and RL (phase-encode direction) acquistion\n",
        "RUN_NAMES = [\n",
        "  \"BAR1\",   # Sweeping Bars repeat 1\n",
        "  \"BAR2\",   # Sweeping Bars repeat 2\n",
        "  \"CCW\",    # Counter Clockwise rotating wedge\n",
        "  \"CW\",     # Clockwise rotating wedge\n",
        "  \"EXP\",    # Expanding ring\n",
        "  \"CON\"     # Contracting ring\n",
        "]"
      ],
      "id": "I7CVWshKz9yC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErP_ocaxK9FU"
      },
      "source": [
        "# Downloading data\n",
        "\n",
        "The files that we provide are:\n",
        "\n",
        " - The whole brain time series data in [CIFTI](https://nipy.org/nibabel/reference/nibabel.cifti2.html#module-nibabel.cifti2.cifti2) format\n",
        " - The stimulus image files as numpy arrays (time x height x width x 3)\n",
        " - surface files for visualisation on the brain"
      ],
      "id": "ErP_ocaxK9FU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fPW7V_aj04vL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Download the data\n",
        "\n",
        "import os, requests, tarfile\n",
        "\n",
        "fname = \"hcp_retino.tgz\"\n",
        "url = \"https://osf.io/d25b4/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      print(f\"Downloading {fname}...\")\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n",
        "      print(f\"Download {fname} completed!\")"
      ],
      "id": "fPW7V_aj04vL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEabsdQI2OxA"
      },
      "outputs": [],
      "source": [
        "# @title Extract the data in `DATA_DIR`\n",
        "fname_ex = \"HCP7T_retino\"\n",
        "path_name = os.path.join(DATA_DIR, fname_ex)\n",
        "if not os.path.exists(path_name):\n",
        "  print(f\"Extracting {fname}...\")\n",
        "  with tarfile.open(f\"{fname}\") as fzip:\n",
        "    fzip.extractall(DATA_DIR)\n",
        "else:\n",
        "  print(f\"File {fname}.tgz has already been extracted.\")"
      ],
      "id": "oEabsdQI2OxA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk6BbsIthZIT"
      },
      "source": [
        "\n",
        "\n",
        "# Helper functions"
      ],
      "id": "Rk6BbsIthZIT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7sNpprtshm5"
      },
      "source": [
        "## load all the data"
      ],
      "id": "y7sNpprtshm5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11MkPa0WpYtg"
      },
      "outputs": [],
      "source": [
        "#load all the data\n",
        "\n",
        "run_exp = 'BAR2'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_PA.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_bar2 = cifti.get_fdata()\n",
        "\n",
        "run_exp = 'EXP'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_AP.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_exp = cifti.get_fdata()\n",
        "\n",
        "run_exp = 'BAR1'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_AP.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_bar1 = cifti.get_fdata()\n",
        "\n",
        "run_exp = 'CON'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_PA.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_con = cifti.get_fdata()\n",
        "\n",
        "run_exp = 'CW'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_PA.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_cw = cifti.get_fdata()\n",
        "\n",
        "run_exp = 'CCW'\n",
        "filename_signal = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_AP.dtseries.nii')\n",
        "cifti = nib.load(filename_signal)\n",
        "time_series_ccw = cifti.get_fdata()\n"
      ],
      "id": "11MkPa0WpYtg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9w1f_Fshdmg"
      },
      "outputs": [],
      "source": [
        "def surf_data_from_cifti(data, cifti, surf_name):\n",
        "  \"\"\"Maps data from cifti file onto a surface\n",
        "\n",
        "  Args:\n",
        "      data : 2D array (nvertices x p)\n",
        "      cifti : Cifti2Image object\n",
        "      surf_name : str (either 'LEFT' or 'RIGHT')\n",
        "  \"\"\"\n",
        "  surf_name_long = 'CIFTI_STRUCTURE_CORTEX_'+surf_name\n",
        "  axis = cifti.header.get_axis(1)  # The brain axis\n",
        "  for name, data_indices, model in axis.iter_structures():\n",
        "    if name == surf_name_long:\n",
        "      vtx_indices = model.vertex\n",
        "      surf_data = np.zeros(axis.nvertices[surf_name_long])\n",
        "      surf_data[vtx_indices] = data[data_indices]\n",
        "      return surf_data\n",
        "  raise ValueError(f\"No structure named {surf_name_long}\")"
      ],
      "id": "B9w1f_Fshdmg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p42YcUUEsmjI"
      },
      "source": [
        "## old hrf"
      ],
      "id": "p42YcUUEsmjI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-GYLBnIkJLFB"
      },
      "outputs": [],
      "source": [
        "# HRF FUNCTION TO MODEL BOLD RESPONSE TO A STIMULUS AT T = 0\n",
        "\n",
        "from scipy.stats import gamma\n",
        "\n",
        "def hrf(t):\n",
        "     \"\"\" Return values for HRF at given times \"\"\"\n",
        "\n",
        "     # Gamma pdf for the peak\n",
        "     peak_values = gamma.pdf(t, 5.7) # peak at about 5 sec\n",
        "\n",
        "     # Gamma pdf for the undershoot\n",
        "     undershoot_values = gamma.pdf(t, 12) # min at about 12 sec\n",
        "\n",
        "     # Combine them\n",
        "     values = peak_values - undershoot_values\n",
        "\n",
        "     # Scale min\n",
        "     values = values / np.min(values) * -0.01 #****work on this\n",
        "\n",
        "     # Scale max\n",
        "     values = values / np.max(values) * 0.5\n",
        "\n",
        "     # return BOLD signal values\n",
        "     return values\n",
        "\n",
        "hrf_times = np.arange(0, 25, 1)\n",
        "hrf_signal = hrf(hrf_times)\n",
        "plt.plot(hrf_times, hrf_signal)\n",
        "plt.axhline(y=0, color='r', linestyle='-')\n",
        "plt.xlabel('time (seconds)')\n",
        "plt.ylabel('BOLD signal')\n",
        "plt.title('Estimated BOLD signal for event at time 0')"
      ],
      "id": "-GYLBnIkJLFB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FippZ-b-svn5"
      },
      "source": [
        "## stacking the data"
      ],
      "id": "FippZ-b-svn5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Cn9R9RNpFHR"
      },
      "outputs": [],
      "source": [
        "# organize and label the data and stimuli\n",
        "# 1 = exp\n",
        "time_series_exp_demean = np.array(time_series_exp)\n",
        "for i in range(91282):\n",
        "  time_series_exp_demean[:, i] -= np.mean(time_series_exp_demean[:, i])\n",
        "time_series_stims = time_series_exp_demean\n",
        "stim_on_exp = stim_area_exp\n",
        "stim_on_exp[stim_on_exp>0] = 1\n",
        "stims_on = stim_on_exp\n",
        "# 2 = con\n",
        "time_series_con_demean = np.array(time_series_con)\n",
        "for i in range(91282):\n",
        "  time_series_con_demean[:, i] -= np.mean(time_series_con_demean[:, i])\n",
        "time_series_stims = np.append(time_series_stims, np.array(time_series_con_demean), 0)\n",
        "stims_on = np.append(stims_on, stim_on_exp*2)\n",
        "# 3 = CW\n",
        "time_series_cw_demean = np.array(time_series_cw)\n",
        "for i in range(91282):\n",
        "  time_series_cw_demean[:, i] -= np.mean(time_series_cw_demean[:, i])\n",
        "time_series_stims = np.append(time_series_stims, np.array(time_series_cw_demean), 0)\n",
        "stim_on_cw = np.append(np.zeros(22), np.append(np.ones(256)*3,np.zeros(22)))\n",
        "stims_on = np.append(stims_on, stim_on_cw)\n",
        "# 4 = BAR1\n",
        "time_series_bar1_demean = np.array(time_series_bar1)\n",
        "for i in range(91282):\n",
        "  time_series_bar1_demean[:, i] -= np.mean(time_series_bar1_demean[:, i])\n",
        "time_series_stims = np.append(time_series_stims, np.array(time_series_bar1_demean), 0)\n",
        "stim_on_bar1 = bar_direction\n",
        "stim_on_bar1[stim_on_bar1>0] = 4\n",
        "stims_on = np.append(stims_on, stim_on_bar1)\n",
        "# 5 = CCW\n",
        "time_series_ccw_demean = np.array(time_series_ccw)\n",
        "for i in range(91282):\n",
        "  time_series_ccw_demean[:, i] -= np.mean(time_series_ccw_demean[:, i])\n",
        "time_series_stims = np.append(time_series_stims, np.array(time_series_ccw_demean), 0)\n",
        "stim_on_cw = np.append(np.zeros(22), np.append(np.ones(256)*5,np.zeros(22)))\n",
        "stims_on = np.append(stims_on, stim_on_ccw)\n",
        "# 6 = BAR2\n",
        "'''time_series_bar2_demean = np.array(time_series_bar2)\n",
        "for i in range(91282):\n",
        "  time_series_bar2_demean[:, i] -= np.mean(time_series_bar2_demean[:, i])\n",
        "time_series_stims = np.append(time_series_stims, np.array(time_series_bar2_demean), 0)\n",
        "stim_on_bar2 = bar_direction\n",
        "stim_on_bar2[stim_on_bar2>0] = 6\n",
        "stims_on = np.append(stims_on, stim_on_bar2)'''"
      ],
      "id": "0Cn9R9RNpFHR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYlJkVGZs1xg"
      },
      "source": [
        "## voxel specific hrf estimate"
      ],
      "id": "kYlJkVGZs1xg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8l6mPd6ovIw"
      },
      "outputs": [],
      "source": [
        "#estimating HRF for every voxel\n",
        "import nideconv as nd\n",
        "\n",
        "rf = nd.ResponseFitter(input_signal=time_series_stims,\n",
        "                            sample_rate=1)\n",
        "stims = [idx for idx, val in enumerate(stims_on) if val != 0]\n",
        "n_regressors = 25\n",
        "\n",
        "rf.add_event(event_name='stim',\n",
        "             onsets=stims,\n",
        "             basis_set='fourier',\n",
        "             n_regressors=n_regressors,\n",
        "             interval=[0,25])\n",
        "\n",
        "rf.fit()\n",
        "\n",
        "hrf_poor = rf.events['stim'].get_timecourses()\n",
        "hrf_est = np.array(hrf_poor)\n",
        "hrf_est.shape"
      ],
      "id": "i8l6mPd6ovIw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfkGV9APL0Xk"
      },
      "source": [
        "# Expanding circle (continuous stim - deprecated)"
      ],
      "id": "hfkGV9APL0Xk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN8lKYOgZTNb"
      },
      "source": [
        "Import time series (BOLD signal) data"
      ],
      "id": "yN8lKYOgZTNb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RbrKHcMZOMF"
      },
      "outputs": [],
      "source": [
        "## TIME SERIES DATA\n",
        "\n",
        "# pick a run\n",
        "run_exp = 'EXP'\n",
        "\n",
        "# define filename\n",
        "filename_signal_exp = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_AP.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_exp = nib.load(filename_signal_exp)\n",
        "\n",
        "time_series_exp = cifti_exp.get_fdata()\n",
        "time_series_exp.shape"
      ],
      "id": "_RbrKHcMZOMF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "danff-AjL8H7"
      },
      "source": [
        "Import & visualize EXP stimulus data"
      ],
      "id": "danff-AjL8H7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFc51pzFu7tn"
      },
      "outputs": [],
      "source": [
        "# define filename\n",
        "filename_stim_exp = os.path.join(DATA_DIR, fname_ex, f'stims/7T_RET{run_exp}.npy')\n",
        "\n",
        "# load the numpy array for the stimulus\n",
        "stim_exp = np.load(filename_stim_exp)\n",
        "\n",
        "# check the shape\n",
        "stim_exp.shape # time x Y (height) x X (width) x 3\n",
        "\n",
        "# define stimulus cycle\n",
        "n_before = 22\n",
        "period = 32\n",
        "cycles = 8\n",
        "n_after = 22\n",
        "\n",
        "def frame(t): # n is frame number\n",
        "\n",
        "    global stim_exp\n",
        "    stim_exp_tmp = stim_exp[t, :, :, :]\n",
        "\n",
        "    plot=plt.imshow(stim_exp_tmp)\n",
        "    return plot\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "stim_frames = np.arange(n_before, n_before + period + 1) # one cycle (running all 300 takes a lot of time)\n",
        "anim = animation.FuncAnimation(fig, frame, frames = stim_frames, blit = False, repeat = True)\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ],
      "id": "tFc51pzFu7tn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCLOITvUOQcx"
      },
      "outputs": [],
      "source": [
        "# DEFINE STIMULUS FUNCTION FOR EXPANDING CIRCLE\n",
        "\n",
        "outer_cycle = np.arange(1, 29)\n",
        "inner_cycle = np.concatenate([[0, 0, 0, 0, 0, 0], np.arange(1, 23)])\n",
        "outer_cycle[22:] = 22\n",
        "outer_radius = np.zeros(300)\n",
        "inner_radius = np.zeros(300)\n",
        "\n",
        "for i in range(8):\n",
        "  outer_radius[(22+i*32):(50+i*32)] = outer_cycle\n",
        "  inner_radius[(22+i*32):(50+i*32)] = inner_cycle\n",
        "\n",
        "plt.plot(np.pi*outer_radius**2-np.pi*inner_radius**2)\n",
        "\n",
        "stim_area = np.pi*outer_radius**2-np.pi*inner_radius**2"
      ],
      "id": "KCLOITvUOQcx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f4omcLxMFYX"
      },
      "source": [
        "Convolve HRF & stimulus to get expected response"
      ],
      "id": "8f4omcLxMFYX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEDW-sNL0D_z"
      },
      "outputs": [],
      "source": [
        "# GLM MODEL\n",
        "constant_exp = np.ones_like(stim_area)\n",
        "X_exp = np.column_stack([constant_exp, (np.convolve(stim_area, hrf_signal)[:300])])\n",
        "\n",
        "theta_hats_exp = np.linalg.inv(X_exp.T @ X_exp) @ X_exp.T @ time_series_exp\n",
        "\n",
        "predicted_time_series_exp = X_exp @ theta_hats_exp"
      ],
      "id": "EEDW-sNL0D_z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWblWlKHRjYT"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_exp[1, :], cifti_exp, 'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "JWblWlKHRjYT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV8o76FEtajg"
      },
      "source": [
        "# CW rotating wedge (continuous stim - deprecated)"
      ],
      "id": "lV8o76FEtajg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQa49q2sH540"
      },
      "outputs": [],
      "source": [
        "## LOAD TIME SERIES DATA\n",
        "\n",
        "# pick a run\n",
        "run_cw = 'CW'\n",
        "\n",
        "# define filename\n",
        "filename_signal_cw = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_cw}_7T_PA.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_cw = nib.load(filename_signal_cw)\n",
        "\n",
        "# extract time series from file\n",
        "time_series_cw = cifti_cw.get_fdata()"
      ],
      "id": "oQa49q2sH540"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGDxWXZqte7W"
      },
      "outputs": [],
      "source": [
        "## LOAD STIM DATA\n",
        "\n",
        "# define filename\n",
        "filename_stim_cw = os.path.join(DATA_DIR, fname_ex, f'stims/7T_RET{run_cw}.npy')\n",
        "\n",
        "# load the numpy array for the stimulus\n",
        "stim_cw = np.load(filename_stim_cw)\n",
        "\n",
        "# check the shape\n",
        "stim_cw.shape # time x Y (height) x X (width) x 3\n",
        "\n",
        "# define stimulus cycle\n",
        "n_before = 22\n",
        "period = 32\n",
        "cycles = 8\n",
        "n_after = 22"
      ],
      "id": "cGDxWXZqte7W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjhw2LEPwT9D"
      },
      "outputs": [],
      "source": [
        "# plot stimulus\n",
        "\n",
        "def frame(t): # n is frame number\n",
        "\n",
        "    global stim_cw\n",
        "    stim_cw_tmp = stim_cw[t, :, :, :]\n",
        "\n",
        "    plot=plt.imshow(stim_cw_tmp)\n",
        "    return plot\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "stim_frames = np.arange(n_before, n_before + period + 1) # one cycle (running all 300 takes a lot of time)\n",
        "anim = animation.FuncAnimation(fig, frame, frames = stim_frames, blit = False, repeat = True)\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ],
      "id": "Zjhw2LEPwT9D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZX0WFy9wUoT"
      },
      "outputs": [],
      "source": [
        "## DEFINE STIMULUS FUNCTION FOR CW ROTATING WEDGE (angle with respect to origin lines)\n",
        "\n",
        "import math\n",
        "\n",
        "# FIND INITIAL ANGLE\n",
        "\n",
        "# get circle center\n",
        "center_y = len(stim_cw[0, :, 0]) / 2 # find y-coord of wedge center\n",
        "center_x = len(stim_cw[0, 0, :]) / 2 # find x-coord of wedge center\n",
        "\n",
        "# find the x-coord of where the white starts at y = 0\n",
        "top_row = np.sum(stim_cw, axis = 3)[22, 0, :]\n",
        "x2 = np.where(top_row == np.amax(top_row))[0][0]\n",
        "\n",
        "# plot\n",
        "plt.imshow(stim_cw[22, :, :, :]) # plot initial frame\n",
        "plt.plot(center_x, center_y, 'ro') # draw point at center\n",
        "plt.plot([center_x, center_x], [center_y, 0], 'r--') # draw straight vertical line at the x-coord of the center\n",
        "plt.plot(x2, 0, 'ro') # draw point where wedge begins\n",
        "plt.plot([center_x, x2], [center_y, 0], 'r--') # draw line from center to where wedge begins\n",
        "\n",
        "# get angle of right triangle (treat center as (0,0))\n",
        "v1 = np.array([0, center_y])\n",
        "v2 = np.array([x2 - center_x, center_y])\n",
        "\n",
        "unit_v1 = v1 / np.linalg.norm(v1)\n",
        "unit_v2 = v2 / np.linalg.norm(v2)\n",
        "\n",
        "initial_angle = np.arccos(np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)) # radians\n",
        "\n",
        "print(initial_angle)"
      ],
      "id": "hZX0WFy9wUoT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlG3OT247rmm"
      },
      "outputs": [],
      "source": [
        "# ADD RADIANS AND FIND COS AS WE ROTATE\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "\n",
        "rate = 2*np.pi / 32 # rad/s\n",
        "stim_time = 300 - n_before - n_after\n",
        "angle = np.zeros(stim_time)\n",
        "cosine = np.zeros(stim_time)\n",
        "\n",
        "for i in range(stim_time):\n",
        "\n",
        "  angle[i] = initial_angle + rate*i\n",
        "  cosine[i] = math.cos(angle[i])\n",
        "\n",
        "# cosine = np.concatenate(([np.nan] * n_before, cosine, [np.nan] * n_after), axis = None) # no cosine before or after stimulus appears\n",
        "plt.plot(cosine)\n",
        "plt.title(\"Angle of the rotating wedge\")\n",
        "# plt.xlim([0, 300])\n",
        "plt.show()"
      ],
      "id": "VlG3OT247rmm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLJE2AydNmv8"
      },
      "outputs": [],
      "source": [
        "## RADIANS AS STIMULUS FUNCTION\n",
        "n_before = 22\n",
        "n_after = 22\n",
        "period = 32\n",
        "rate = 2*np.pi / period # rad/s\n",
        "stim_time = 300 - n_before - n_after\n",
        "\n",
        "radians = np.arange(start = initial_angle, stop = initial_angle + 2*np.pi, step = rate)\n",
        "angle = np.tile(radians, 8)\n",
        "\n",
        "plt.plot(angle)\n",
        "# plt.xlim([0, 300])\n",
        "plt.show()"
      ],
      "id": "VLJE2AydNmv8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXGvswj7D5-G"
      },
      "outputs": [],
      "source": [
        "# GLM MODEL\n",
        "constant = np.ones_like(cosine)\n",
        "X_cw = np.column_stack([constant, (np.convolve(cosine, hrf_signal)[:len(cosine)])])\n",
        "\n",
        "theta_hats_cw = np.linalg.inv(X_cw.T @ X_cw) @ X_cw.T @ time_series_cw[n_before:(300 - n_after)]\n",
        "\n",
        "predicted_time_series_cw = X_cw @ theta_hats_cw"
      ],
      "id": "wXGvswj7D5-G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPmnJ-sWdyw3"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.convolve(angle, hrf_signal)[:len(angle)])"
      ],
      "id": "EPmnJ-sWdyw3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z1_ydilebvf"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.convolve(cosine, hrf_signal)[:len(cosine)])"
      ],
      "id": "7z1_ydilebvf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWbc8EOqEJ5u"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_cw[1, :], cifti_cw,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "RWbc8EOqEJ5u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsPCAgqPyRq1"
      },
      "source": [
        "**CCW stimulus:**"
      ],
      "id": "bsPCAgqPyRq1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH1FuL33yfJO"
      },
      "outputs": [],
      "source": [
        "# pick a run\n",
        "run_cw = 'CCW'\n",
        "\n",
        "# define filename\n",
        "filename_signal_exp = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_cw}_7T_AP.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_exp = nib.load(filename_signal_exp)\n",
        "\n",
        "time_series_exp = cifti_exp.get_fdata()\n",
        "time_series_exp.shape"
      ],
      "id": "OH1FuL33yfJO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmkh9uRqyj2D"
      },
      "outputs": [],
      "source": [
        "## LOAD STIM DATA\n",
        "\n",
        "# define filename\n",
        "filename_stim_cw = os.path.join(DATA_DIR, fname_ex, f'stims/7T_RET{run_cw}.npy')\n",
        "\n",
        "# load the numpy array for the stimulus\n",
        "stim_cw = np.load(filename_stim_cw)\n",
        "\n",
        "# check the shape\n",
        "stim_cw.shape # time x Y (height) x X (width) x 3\n",
        "\n",
        "# define stimulus cycle\n",
        "n_before = 22\n",
        "period = 32\n",
        "cycles = 8\n",
        "n_after = 22"
      ],
      "id": "cmkh9uRqyj2D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3bJlHP4yqDv"
      },
      "outputs": [],
      "source": [
        "# plot stimulus\n",
        "\n",
        "def frame(t): # n is frame number\n",
        "\n",
        "    global stim_cw\n",
        "    stim_cw_tmp = stim_cw[t, :, :, :]\n",
        "\n",
        "    plot=plt.imshow(stim_cw_tmp)\n",
        "    return plot\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "stim_frames = np.arange(n_before, n_before + period + 1) # one cycle (running all 300 takes a lot of time)\n",
        "anim = animation.FuncAnimation(fig, frame, frames = stim_frames, blit = False, repeat = True)\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ],
      "id": "B3bJlHP4yqDv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0gL6q7eyw9r"
      },
      "outputs": [],
      "source": [
        "## DEFINE STIMULUS FUNCTION FOR CW ROTATING WEDGE (angle with respect to origin lines)\n",
        "\n",
        "import math\n",
        "import cv2\n",
        "# FIND INITIAL ANGLE\n",
        "\n",
        "# get circle center\n",
        "center_y = len(stim_cw[0, :, 0]) / 2 # find y-coord of wedge center\n",
        "center_x = len(stim_cw[0, 0, :]) / 2 # find x-coord of wedge center\n",
        "\n",
        "#Load the first frame at time 22s:\n",
        "im = stim_cw[22, :, :, :]\n",
        "#create grey image (we cant create a B&W image directly):\n",
        "grayImage = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "#create full black and white image:\n",
        "(thresh, blackAndWhiteImage) = cv2.threshold(grayImage, 10, 255, cv2.THRESH_BINARY)\n",
        "#Get all the X and Y coordinates where the coulour is white:\n",
        "(Xw, Yw) = np.where(blackAndWhiteImage==255)\n",
        "#Get the x coordinate where the white starts:\n",
        "x2 = np.amax(Xw)\n",
        "\n",
        "# plot\n",
        "plt.imshow(stim_cw[22, :, :, :]) # plot initial frame\n",
        "plt.plot(center_x, center_y, 'ro') # draw point at center\n",
        "plt.plot([center_x, center_x], [center_y, 0], 'r--') # draw straight vertical line at the x-coord of the center\n",
        "plt.plot(x2, 0, 'ro') # draw point where wedge begins\n",
        "plt.plot([center_x, x2], [center_y, 0], 'r--') # draw line from center to where wedge begins\n",
        "\n",
        "# get angle of right triangle (treat center as (0,0))\n",
        "v1 = np.array([0, center_y])\n",
        "v2 = np.array([x2 - center_x, center_y])\n",
        "\n",
        "unit_v1 = v1 / np.linalg.norm(v1)\n",
        "unit_v2 = v2 / np.linalg.norm(v2)\n",
        "\n",
        "initial_angle = np.arccos(np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)) # radians\n",
        "\n",
        "print (initial_angle)\n"
      ],
      "id": "A0gL6q7eyw9r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JqnGx_7y2i_"
      },
      "outputs": [],
      "source": [
        "# ADD RADIANS AND FIND COS AS WE ROTATE\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "\n",
        "rate = 2*np.pi / 32 # rad/s\n",
        "stim_time = 300 - n_before - n_after\n",
        "angle = np.zeros(stim_time)\n",
        "cosine = np.zeros(stim_time)\n",
        "\n",
        "for i in range(stim_time):\n",
        "\n",
        "  angle[i] = initial_angle + rate*i\n",
        "  cosine[i] = math.cos(angle[i])\n",
        "\n",
        "# cosine = np.concatenate(([np.nan] * n_before, cosine, [np.nan] * n_after), axis = None) # no cosine before or after stimulus appears\n",
        "plt.plot(cosine)\n",
        "plt.title(\"Angle of the rotating wedge\")\n",
        "# plt.xlim([0, 300])\n",
        "plt.show()"
      ],
      "id": "4JqnGx_7y2i_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQfOpplEy-gm"
      },
      "outputs": [],
      "source": [
        "## RADIANS AS STIMULUS FUNCTION\n",
        "n_before = 22\n",
        "n_after = 22\n",
        "period = 32\n",
        "rate = 2*np.pi / period # rad/s\n",
        "stim_time = 300 - n_before - n_after\n",
        "\n",
        "radians = np.arange(start = initial_angle, stop = initial_angle + 2*np.pi, step = rate)\n",
        "angle = np.tile(radians, 8)\n",
        "\n",
        "plt.plot(angle)\n",
        "# plt.xlim([0, 300])\n",
        "plt.show()"
      ],
      "id": "eQfOpplEy-gm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om0AhtNsrTrn"
      },
      "source": [
        "# Moving bars (continuous stim - deprecated)"
      ],
      "id": "om0AhtNsrTrn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBdhCULlLUA3"
      },
      "outputs": [],
      "source": [
        "## LOAD TIME SERIES DATA\n",
        "\n",
        "# pick a run\n",
        "run_bar1 = 'BAR1'\n",
        "\n",
        "# define filename\n",
        "filename_signal_bar1 = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_bar1}_7T_AP.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_bar1 = nib.load(filename_signal_bar1)\n",
        "\n",
        "# extract time series from file\n",
        "time_series_bar1 = cifti_bar1.get_fdata()"
      ],
      "id": "hBdhCULlLUA3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMzfbiqRrg8n"
      },
      "outputs": [],
      "source": [
        "## LOAD STIM DATA\n",
        "\n",
        "# define filename\n",
        "filename_bar1 = os.path.join(DATA_DIR, fname_ex, f'stims/7T_RET{run_bar1}.npy')\n",
        "\n",
        "# load the numpy array for the stimulus\n",
        "stim_bar1 = np.load(filename_bar1)\n",
        "\n",
        "# check the shape\n",
        "stim_bar1.shape # time x Y (height) x X (width) x 3\n",
        "\n",
        "# define stimulus cycle\n",
        "n_before = 16\n",
        "period = 28\n",
        "cycles = 8\n",
        "n_after = 20\n",
        "\n",
        "def frame(t): # n is frame number\n",
        "\n",
        "    global stim_bar1\n",
        "    stim_bar1_tmp = stim_bar1[t, :, :, :]\n",
        "\n",
        "    plot=plt.imshow(stim_bar1_tmp)\n",
        "    return plot\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "stim_frames = np.arange(142+n_before, 206+n_before + period + 1) # one cycle (running all 300 takes a lot of time)\n",
        "anim = animation.FuncAnimation(fig, frame, frames = stim_frames, blit = False, repeat = True)\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())"
      ],
      "id": "xMzfbiqRrg8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agfvNelTvmx_"
      },
      "outputs": [],
      "source": [
        "#using the direction of movement, and position along that direction as parameters\n",
        "\n",
        "#position of the moving bar\n",
        "bar_area = np.sum(np.sum(np.sum(stim_bar1, 1), 1), 1) #area of the bar\n",
        "bar_position = bar_area\n",
        "bar_position[bar_position>0] = 1 # periods when bar is present\n",
        "for i in range(299):\n",
        "  if (bar_position[i+1] > 0 and bar_position[i]>0): bar_position[i+1] = bar_position[i] + 1 #constant bar movement along the direction\n",
        "\n",
        "#direction of movement: L-R, B-T, R-L, T-B, BL-TR, BR-TL, TR-BL, TL-BR\n",
        "bar_direction = np.zeros((300))\n",
        "bar_directions = [90, 360, 270, 180, 45, 315, 225, 135] #assuming 0deg is pointing up and going clockwise\n",
        "bar_periods = [np.arange(16, (16+28)), np.arange((1*32+16), (1*32+16+28)), np.arange((2*32+16),(2*32+16+28)), np.arange((3*32+16),(3*32+16+28)), np.arange((142+0*32+16),(142+0*32+16+28)), np.arange((142+1*32+16),(142+1*32+16+28)), np.arange((142+2*32+16),(142+2*32+16+28)), np.arange((142+3*32+16),(142+3*32+16+28))]\n",
        "for i in range(8):\n",
        "  bar_direction[bar_periods[i]] = bar_directions[i]\n",
        "bar_cos = np.cos(bar_direction/180*np.pi)\n",
        "plt.title(\"Position along the direction\")\n",
        "plt.plot(bar_direction)"
      ],
      "id": "agfvNelTvmx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o1rPGWc0dYf"
      },
      "outputs": [],
      "source": [
        "#GLM model\n",
        "constant = np.ones_like(bar_direction)\n",
        "X_bar1 = np.column_stack([constant, (np.convolve(bar_direction, hrf_signal)[:len(bar_direction)]), (np.convolve(bar_position, hrf_signal)[:len(bar_position)])])\n",
        "\n",
        "theta_hats_bar1 = np.linalg.inv(X_bar1.T @ X_bar1) @ X_bar1.T @ time_series_bar1\n",
        "\n",
        "predicted_time_series_cw = X_bar1 @ theta_hats_bar1"
      ],
      "id": "7o1rPGWc0dYf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnZC0WN24QqQ"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_bar1[1, :], cifti,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "hnZC0WN24QqQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOb2df2tv8Lv"
      },
      "source": [
        "## SVM"
      ],
      "id": "hOb2df2tv8Lv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjZ7k1u1v9ce"
      },
      "outputs": [],
      "source": [
        "# convert Y to integer (not float)\n",
        "\n",
        "bar_direction_int = [int(x/45) for x in bar_direction]\n",
        "bar_position_int = [int((x+3)/4) for x in bar_position]\n",
        "\n",
        "plt.plot(bar_position_int)"
      ],
      "id": "RjZ7k1u1v9ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8cU801Yv_P1"
      },
      "outputs": [],
      "source": [
        "# Dimensionality reduction on time series (reduce # of voxels to avoid overfitting)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# number of components for each feature\n",
        "n_comps_dir = 14\n",
        "n_comps_pos = 12\n",
        "\n",
        "# Initializes PCA\n",
        "pca_model_dir = PCA(n_components = n_comps_dir)\n",
        "pca_model_pos = PCA(n_components = n_comps_pos)\n",
        "\n",
        "# Performs PCA\n",
        "pca_model_dir.fit(time_series_bar1)\n",
        "pca_model_pos.fit(time_series_bar1)\n",
        "\n",
        "# get PCA scores\n",
        "time_scores_bar1_dir = pca_model_dir.transform(time_series_bar1)\n",
        "time_scores_bar1_pos = pca_model_pos.transform(time_series_bar1)\n",
        "\n",
        "# check shape\n",
        "time_scores_bar1_dir.shape"
      ],
      "id": "B8cU801Yv_P1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baPu0mpwwAdG"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and  test data:\n",
        "# data for SVM\n",
        "X1 = time_scores_bar1_dir\n",
        "X2 = time_scores_bar1_pos\n",
        "Y1 = bar_direction_int\n",
        "Y2 = bar_position_int\n",
        "# label matrices, 0 is direction data, 1 is position data\n",
        "XZ1 = np.zeros_like(X1)\n",
        "XZ2 = np.ones_like(X2)\n",
        "YZ1 = np.zeros_like(Y1)\n",
        "YZ2 = np.ones_like(Y2)\n",
        "# stack everything together for splitting\n",
        "X = np.append(X1, X2, 1)\n",
        "Y = np.vstack([Y1, Y2]).T\n",
        "XZ = np.append(XZ1, XZ2, 1)\n",
        "YZ = np.vstack([YZ1, YZ2]).T\n",
        "# split\n",
        "X_train, X_test, Y_train, Y_test, XZ_train, XZ_test, YZ_train, YZ_test = train_test_split(X,Y,XZ,YZ, test_size = .2) # random state depend on how the data looks like (we might need to shuffle it)\n",
        "# recover data from stack\n",
        "X1_train = np.reshape(X_train[XZ_train==0], (-1, n_comps_dir))\n",
        "X2_train = np.reshape(X_train[XZ_train==1], (-1, n_comps_pos))\n",
        "Y1_train = Y_train[YZ_train==0]\n",
        "Y2_train = Y_train[YZ_train==1]\n",
        "X1_test = np.reshape(X_test[XZ_test==0], (-1, n_comps_dir))\n",
        "X2_test = np.reshape(X_test[XZ_test==1], (-1, n_comps_pos))\n",
        "Y1_test = Y_test[YZ_test==0]\n",
        "Y2_test = Y_test[YZ_test==1]\n",
        "\n",
        "# Implement SVM:\n",
        "SVM_classifier_dir = svm.SVC(kernel='rbf', max_iter=1e6, C=1e3) # Type of Kernel can be changed later 'rbf' is a good other option\n",
        "SVM_classifier_pos = svm.SVC(kernel='rbf', max_iter=1e6, C=1e2)\n",
        "# train the model\n",
        "SVM_classifier_dir.fit(X1_train,Y1_train)\n",
        "SVM_classifier_pos.fit(X2_train,Y2_train)\n",
        "\n",
        "# predict the response:\n",
        "predictions_dir = SVM_classifier_dir.predict(X1_test)\n",
        "predictions_pos = SVM_classifier_pos.predict(X2_test)"
      ],
      "id": "baPu0mpwwAdG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD9SHt0OwBnO"
      },
      "outputs": [],
      "source": [
        "# Evaluation of the model:\n",
        "predictions = np.vstack([predictions_dir, predictions_pos]).T\n",
        "#count for how many indices both values are correct\n",
        "counter = 0\n",
        "for i in range(np.size(predictions,0)):\n",
        "  if (predictions[i, 0] == Y_test[i, 0] and predictions[i, 1] == Y_test[i, 1]): counter += 1\n",
        "\n",
        "print('TOTAL ACCURACY = ' + str(counter/np.size(predictions, 0)))\n",
        "print(' ')\n",
        "print('directions:')\n",
        "print('accuracy', metrics.accuracy_score(Y1_test, predictions_dir))\n",
        "print(metrics.classification_report(Y1_test, predictions_dir))\n",
        "confusion_matrix = metrics.confusion_matrix(Y1_test, predictions_dir)\n",
        "print(confusion_matrix)\n",
        "\n",
        "print('positions:')\n",
        "print('accuracy', metrics.accuracy_score(Y2_test, predictions_pos))\n",
        "print(metrics.classification_report(Y2_test, predictions_pos))\n",
        "confusion_matrix = metrics.confusion_matrix(Y2_test, predictions_pos)\n",
        "print(confusion_matrix)\n",
        "\n",
        "\n",
        "print('combined:')\n",
        "print('accuracy '+ str(counter/np.size(predictions, 0)))"
      ],
      "id": "pD9SHt0OwBnO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMxE9M93Zxrb"
      },
      "source": [
        "# Expanding circle (discrete stim)"
      ],
      "id": "RMxE9M93Zxrb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZbdTq4iaXgy"
      },
      "source": [],
      "id": "KZbdTq4iaXgy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4GW4kgXguFd"
      },
      "outputs": [],
      "source": [
        "## CW STIMULUS MATRIX\n",
        "\n",
        "# define stimulus cycle\n",
        "n_before = 22\n",
        "period = 32\n",
        "cycles = 8\n",
        "n_after = 22\n",
        "\n",
        "import math\n",
        "\n",
        "# FIND INITIAL ANGLE\n",
        "\n",
        "# get circle center\n",
        "center_y = len(stim_cw[0, :, 0]) / 2 # find y-coord of wedge center\n",
        "center_x = len(stim_cw[0, 0, :]) / 2 # find x-coord of wedge center\n",
        "\n",
        "# find the x-coord of where the white starts at y = 0\n",
        "top_row = np.sum(stim_cw, axis = 3)[22, 0, :]\n",
        "x2 = np.where(top_row == np.amax(top_row))[0][0]\n",
        "\n",
        "# get angle of right triangle (treat center as (0,0))\n",
        "v1 = np.array([0, center_y])\n",
        "v2 = np.array([x2 - center_x, center_y])\n",
        "\n",
        "inner = np.inner(v1, v2)\n",
        "norms = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "\n",
        "cos = inner / norms\n",
        "rad = np.arccos(np.clip(cos, -1.0, 1.0)) # radians\n",
        "\n",
        "# add 45 degrees (pi/180 rad) to get center\n",
        "initial_angle = rad + np.deg2rad(45)"
      ],
      "id": "W4GW4kgXguFd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCvbXjcWmJCX"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "plt.imshow(stim_cw[22, :, :, :]) # plot initial frame\n",
        "plt.plot(center_x, center_y, 'ro') # draw point at center\n",
        "plt.plot([center_x, center_x], [center_y, 0], 'r--') # draw straight vertical line at the x-coord of the center\n",
        "plt.plot(x2, 0, 'ro') # draw point where wedge begins\n",
        "plt.plot([center_x, x2], [center_y, 0], 'r--') # draw line from center to where wedge begins\n",
        "\n",
        "mid_x = 144*np.cos(initial_angle)\n",
        "mid_y = 144*np.cos(np.deg2rad(180) - initial_angle)\n",
        "\n",
        "plt.plot(center_x + mid_x, center_y + mid_y, 'ro')\n",
        "plt.show()\n",
        "center_y"
      ],
      "id": "cCvbXjcWmJCX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkBwGTeuh-n2"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# discrete stimulus: each angle is an event\n",
        "\n",
        "total_rad = 2 * np.pi\n",
        "rate = total_rad / period # rad/s\n",
        "stim_time = 300 - n_before - n_after\n",
        "\n",
        "one_cycle = np.arange(start = initial_angle, stop = initial_angle + total_rad, step = rate)\n",
        "\n",
        "for r in range(len(one_cycle)):\n",
        "  if one_cycle[r] >= total_rad:\n",
        "    one_cycle[r] = one_cycle[r] - total_rad\n",
        "\n",
        "full_stim_cw = np.tile(one_cycle, 8)\n",
        "full_stim_cw = list(itertools.chain([0] * n_before, full_stim_cw.tolist(), [0] * n_after))\n",
        "\n",
        "plt.plot(full_stim_cw, 'ro')\n",
        "plt.vlines(np.arange(start = n_before, stop = n_before + stim_time, step = period), ymin = 0, ymax = total_rad, linestyles = \"--\")\n",
        "# one_cycle"
      ],
      "id": "TkBwGTeuh-n2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZBaVywQoFPg"
      },
      "outputs": [],
      "source": [
        "# create design matrix\n",
        "\n",
        "d_cw = {\"time\": range(300),\n",
        "    \"event\": full_stim_cw\n",
        "     }\n",
        "\n",
        "df_design_mat_cw = pd.DataFrame(d_cw)\n",
        "df_design_mat_cw = pd.get_dummies(df_design_mat_cw[\"event\"])\n",
        "design_mat_cw = df_design_mat_cw.to_numpy()\n",
        "\n",
        "dm_cw = Design_Matrix(design_mat_cw,\n",
        "              sampling_freq = 1,\n",
        "              columns = df_design_mat_cw.columns)\n",
        "\n",
        "dm_cw.heatmap()\n",
        "\n",
        "# dm_with_cosine = dm.add_dct_basis(duration = 20)\n",
        "# dm_with_cosine.heatmap()"
      ],
      "id": "gZBaVywQoFPg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8XzVFvBfTrm"
      },
      "outputs": [],
      "source": [
        "# Convolve each angle event with HRF\n",
        "\n",
        "padding = len(hrf_signal) - 1\n",
        "padded_stim_cw = np.concatenate([np.zeros((padding, design_mat_cw.shape[1])), design_mat_cw])\n",
        "\n",
        "design_mat_convolved_cw= np.zeros(padded_stim_cw.shape)\n",
        "for i in range(design_mat_cw.shape[1]):\n",
        "  design_mat_convolved_cw[:, i] = np.convolve(design_mat_cw[:, i], hrf_signal)"
      ],
      "id": "m8XzVFvBfTrm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo-YmGJTuG5E"
      },
      "outputs": [],
      "source": [
        "# GLM MODEL\n",
        "\n",
        "constant = np.ones(padded_stim_cw.shape[0])\n",
        "X_cw = np.column_stack([constant, design_mat_convolved_cw])[n_before:(300 - n_after)]\n",
        "\n",
        "theta_hats_cw = np.linalg.inv(X_cw.T @ X_cw) @ X_cw.T @ time_series_cw[n_before:(300 - n_after)]\n",
        "\n",
        "predicted_time_series_cw = X_cw @ theta_hats_cw"
      ],
      "id": "wo-YmGJTuG5E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGxMLlxvuTlf"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_cw[1, :], cifti_cw,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "qGxMLlxvuTlf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCwgl8NHtVWF"
      },
      "source": [
        "**TO IMPROVE:**"
      ],
      "id": "nCwgl8NHtVWF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOBEyD6FtT6u"
      },
      "source": [
        "**GLM model: Compressive spatial summation in the human visual cortex**\n",
        "\n",
        "Kay et al., 2013\n",
        "\n",
        "**accounts for nonlinear effect in spatial summation*\n",
        "\n",
        "\"The GLM analysis deconvolves an HRF from the raw time-series data of each voxel to estimate the voxel response amplitude to each aperature; the pRF analyses are the outputs of the GLM analysis rather than the raw time-series data\"\n",
        "\n",
        "* voxel-specific HRF can be estimated directly from the data (finite impulse response - FIR; Dale, 1999)\n",
        "* low-frequency fluctuation - use polynomials as regressors for the baseline signal level\n",
        "* reduce overfitting of FIR model by incorporating time-event separability\n",
        "\n",
        "**to consider if we want to improve our HRF modeling (instead of just using canonical for all voxels/regions):**\n",
        "\n",
        "* FIR - BOLD signal assumed to be a linear, time-invariant system with respect to the stimulus\n",
        "* HDR estimated for each stimulus event type using a set of shifted delta functions as regressors (no assumption on shape of HDR)\n",
        "* two types of effects: stimulus effects (transient HDRs to stimulus events) & nuisance effects (persistent baseline signal that may vary over time)\n",
        "\n",
        "\n",
        "* e = number of event types\n",
        "* I = number of time points in one HDR\n",
        "* m = number of nuisance terms\n",
        "* t = number of time-series data points\n",
        "\n",
        "time-series data modeled as y = Xh + Sb + n\n",
        "* y = data (t x 1)\n",
        "* X = stimulus matrix (t x el); concatenation of the stimulus convolution matrix for each event type; consists of shifted versions of a binary sequence, where ones indicate event occurrences\n",
        "* h = concatenation of the HDR associated with each event type (el x 1)\n",
        "* S = nuiasnce matrix (t x m)\n",
        "* b = set of nuisance params (m x 1)\n",
        "* n = noise term (t x 1)"
      ],
      "id": "sOBEyD6FtT6u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1sui5yKta3e"
      },
      "source": [
        "**Angle of stimulus (ellipse, not circle)**"
      ],
      "id": "K1sui5yKta3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r15J1r8to5E"
      },
      "outputs": [],
      "source": [
        "# find circle edges\n",
        "stim_cw_sum = np.sum(stim_cw, axis = 3)\n",
        "\n",
        "# bin rgb variable\n",
        "  # white is (R = 255, G = 255, B = 255) (765)\n",
        "  # black is (R = 0, G = 0, B = 0)\n",
        "\n",
        "stim_cw_bin = np.zeros(stim_cw_sum.shape)\n",
        "for i in range(300):\n",
        "  for h in range(stim_cw_sum.shape[1]):\n",
        "    stim_cw_bin[i, h, :] = np.digitize(stim_cw_sum[i, h, :], bins = (50, 700))\n",
        "\n",
        "# find edges (bin = 1)\n",
        "\n",
        "borders = []\n",
        "for i in range(300):\n",
        "    stim_slice = stim_cw_bin[i, :, :]\n",
        "    X = np.argwhere(stim_slice == 1)\n",
        "\n",
        "    borders.append(X)"
      ],
      "id": "5r15J1r8to5E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnMZnGGNjn_U"
      },
      "outputs": [],
      "source": [
        "plt.plot(borders[22][:, 0], borders[22][:, 1], 'ro', alpha = 0.5)\n",
        "# plt.xlim([0, stim_cw_bin.shape[2]])\n",
        "# plt.ylim([stim_cw_bin.shape[1], 0])"
      ],
      "id": "cnMZnGGNjn_U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQWn77nDxJ-5"
      },
      "source": [
        "# EXP/CON ring (discrete stim)"
      ],
      "id": "fQWn77nDxJ-5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY_USsaiyifA"
      },
      "source": [
        "time series data"
      ],
      "id": "JY_USsaiyifA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn-qNih7xNsA"
      },
      "outputs": [],
      "source": [
        "# pick a run\n",
        "run_exp = 'EXP'\n",
        "\n",
        "# define filename\n",
        "filename_signal_exp = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_exp}_7T_AP.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_exp = nib.load(filename_signal_exp)\n",
        "\n",
        "time_series_exp = cifti_exp.get_fdata()"
      ],
      "id": "Hn-qNih7xNsA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw_mEQCFyg0S"
      },
      "source": [
        "stimulus data"
      ],
      "id": "Hw_mEQCFyg0S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oM0cwpgFyf5W"
      },
      "outputs": [],
      "source": [
        "# define filename\n",
        "filename_stim_exp = os.path.join(DATA_DIR, fname_ex, f'stims/7T_RET{run_exp}.npy')\n",
        "\n",
        "# load the numpy array for the stimulus\n",
        "stim_exp = np.load(filename_stim_exp)\n",
        "\n",
        "# check the shape\n",
        "stim_exp.shape # time x Y (height) x X (width) x 3\n"
      ],
      "id": "oM0cwpgFyf5W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6XWNROhVzQ5W"
      },
      "outputs": [],
      "source": [
        "# plot stim\n",
        "plt.imshow(stim_exp[54, :, :, :])\n",
        "\n",
        "# outer appears at 22s\n",
        "# outer stops expanding at 44s\n",
        "\n",
        "# inner appears at 27s\n",
        "# inner disappears at 50s"
      ],
      "id": "6XWNROhVzQ5W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_H4dnejyo1S"
      },
      "source": [
        "define stimulus as discrete event at each time point"
      ],
      "id": "V_H4dnejyo1S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oW-yhaBKyrgH"
      },
      "outputs": [],
      "source": [
        "# define stimulus cycle\n",
        "n_before = 22\n",
        "period = 32\n",
        "cycles = 8\n",
        "n_after = 22\n",
        "stim_time = 300 - n_before - n_after\n",
        "\n",
        "# find area at each time point\n",
        "outer_cycle = np.arange(1, 29)\n",
        "outer_cycle[22:] = 22\n",
        "inner_cycle = np.concatenate([[0] * 6, np.arange(1, 23)])\n",
        "\n",
        "outer_radius = np.zeros(300)\n",
        "inner_radius = np.zeros(300)\n",
        "\n",
        "for i in range(8):\n",
        "  outer_radius[(22 + i*32):(50 + i*32)] = outer_cycle\n",
        "  inner_radius[(22 + i*32):(50 + i*32)] = inner_cycle\n",
        "\n",
        "# calculate area and round to nearest integer (for SVM)\n",
        "stim_area_exp = np.pi*outer_radius**2-np.pi*inner_radius**2\n",
        "stim_area_exp_int = [int(x) for x in stim_area_exp]"
      ],
      "id": "oW-yhaBKyrgH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TgHlwSsN3ktS"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "plt.plot(stim_area_exp_int, 'ro')\n",
        "plt.vlines(np.arange(start = n_before, stop = n_before + stim_time, step = period), ymin = 0, ymax = np.max(stim_area_exp_int), linestyles = \"--\")"
      ],
      "id": "TgHlwSsN3ktS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCDJLtsHzHim"
      },
      "source": [
        "create design matrix"
      ],
      "id": "wCDJLtsHzHim"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pTPqBzCvzJEy"
      },
      "outputs": [],
      "source": [
        "d_exp = {\"time\": range(300),\n",
        "    \"event\": stim_area_exp_int\n",
        "     }\n",
        "\n",
        "df_design_mat_exp = pd.DataFrame(d_exp)\n",
        "df_design_mat_exp = pd.get_dummies(df_design_mat_exp[\"event\"])\n",
        "design_mat_exp = df_design_mat_exp.to_numpy()\n",
        "\n",
        "dm_exp = Design_Matrix(design_mat_exp,\n",
        "              sampling_freq = 1,\n",
        "              columns = df_design_mat_exp.columns)\n",
        "\n",
        "dm_exp.heatmap()\n",
        "\n",
        "# dm_with_cosine = dm.add_dct_basis(duration = 20)\n",
        "# dm_with_cosine.heatmap()"
      ],
      "id": "pTPqBzCvzJEy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qD-Erugs4MTi"
      },
      "outputs": [],
      "source": [
        "# Convolve each area event with HRF\n",
        "\n",
        "padding = len(hrf_signal) - 1\n",
        "padded_stim_exp = np.concatenate([np.zeros((padding, design_mat_exp.shape[1])), design_mat_exp])\n",
        "\n",
        "design_mat_convolved_exp = np.zeros(padded_stim_exp.shape)\n",
        "for i in range(design_mat_exp.shape[1]):\n",
        "  design_mat_convolved_exp[:, i] = np.convolve(design_mat_exp[:, i], hrf_signal)"
      ],
      "id": "qD-Erugs4MTi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E36nW0t64vyQ"
      },
      "outputs": [],
      "source": [
        "# GLM MODEL\n",
        "\n",
        "constant = np.ones(padded_stim_exp.shape[0])\n",
        "X_exp = np.column_stack([constant, design_mat_convolved_exp])[n_before:(300 - n_after)]\n",
        "\n",
        "theta_hats_exp = np.linalg.inv(X_exp.T @ X_exp) @ X_exp.T @ time_series_exp[n_before:(300 - n_after)]\n",
        "\n",
        "predicted_time_series_exp = X_exp @ theta_hats_exp"
      ],
      "id": "E36nW0t64vyQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOTMyP3t492d"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_exp[1, :], cifti_exp,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "gOTMyP3t492d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E4NqAUh5Vgn"
      },
      "source": [
        "CON (EXP reversed)"
      ],
      "id": "8E4NqAUh5Vgn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_B0WvRE66rx"
      },
      "outputs": [],
      "source": [
        "# get time series for contracting ring\n",
        "\n",
        "# pick a run\n",
        "run_con = 'CON'\n",
        "\n",
        "# define filename\n",
        "filename_signal_con = os.path.join(DATA_DIR, fname_ex, f'tfMRI_RET{run_con}_7T_PA.dtseries.nii')\n",
        "\n",
        "# load the file with nibabel\n",
        "cifti_con = nib.load(filename_signal_con)\n",
        "\n",
        "# extract time series data\n",
        "time_series_con = cifti_con.get_fdata()"
      ],
      "id": "r_B0WvRE66rx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f523DGE5W5A"
      },
      "outputs": [],
      "source": [
        "# reverse expanding ring to get contracting ring\n",
        "stim_area_con_int = stim_area_exp_int[::-1]"
      ],
      "id": "2f523DGE5W5A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M2tXPm15mPz"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "plt.plot(stim_area_con_int, 'ro')\n",
        "plt.vlines(np.arange(start = n_before, stop = n_before + stim_time, step = period), ymin = 0, ymax = np.max(stim_area_con_int), linestyles = \"--\")"
      ],
      "id": "-M2tXPm15mPz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l9f-cCmI6CkW"
      },
      "outputs": [],
      "source": [
        "# design matrix\n",
        "\n",
        "d_con = {\"time\": range(300),\n",
        "    \"event\": stim_area_con_int\n",
        "     }\n",
        "\n",
        "df_design_mat_con = pd.DataFrame(d_con)\n",
        "df_design_mat_con = pd.get_dummies(df_design_mat_con[\"event\"])\n",
        "design_mat_con = df_design_mat_con.to_numpy()\n",
        "\n",
        "dm_con = Design_Matrix(design_mat_con,\n",
        "              sampling_freq = 1,\n",
        "              columns = df_design_mat_con.columns)\n",
        "\n",
        "dm_con.heatmap()"
      ],
      "id": "l9f-cCmI6CkW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0mQwZoU76TpE"
      },
      "outputs": [],
      "source": [
        "# Convolve each area event with HRF\n",
        "\n",
        "padding = len(hrf_signal) - 1\n",
        "padded_stim_con = np.concatenate([np.zeros((padding, design_mat_con.shape[1])), design_mat_con])\n",
        "\n",
        "design_mat_convolved_con = np.zeros(padded_stim_con.shape)\n",
        "for i in range(design_mat_con.shape[1]):\n",
        "  design_mat_convolved_con[:, i] = np.convolve(design_mat_con[:, i], hrf_signal)"
      ],
      "id": "0mQwZoU76TpE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UXMxiNhA6d-d"
      },
      "outputs": [],
      "source": [
        "# GLM MODEL\n",
        "\n",
        "constant = np.ones(padded_stim_con.shape[0])\n",
        "X_con = np.column_stack([constant, design_mat_convolved_con])[n_before:(300 - n_after)]\n",
        "\n",
        "theta_hats_con = np.linalg.inv(X_con.T @ X_con) @ X_con.T @ time_series_con[n_before:(300 - n_after)]\n",
        "\n",
        "predicted_time_series_con = X_con @ theta_hats_con"
      ],
      "id": "UXMxiNhA6d-d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQDvtRpt6vQL"
      },
      "outputs": [],
      "source": [
        "# PLOT THETA WEIGHTS ON BRAIN\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(theta_hats_con[1, :], cifti_con,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "tQDvtRpt6vQL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsRn5BS8_kz0"
      },
      "source": [
        "T-contrast"
      ],
      "id": "jsRn5BS8_kz0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sa-rlsUx7TvB"
      },
      "outputs": [],
      "source": [
        "# WHERE IS EXP MORE INTERESTING THAN CON?? (T-CONTRAST)\n",
        "cope_1_neg1 = 1 * theta_hats_exp + -1 * theta_hats_con\n",
        "t_1_neg1 = cope_1_neg1/np.std(cope_1_neg1)\n",
        "\n",
        "# WHERE IS CON MORE INTERESTING THAN EXP?? (T-CONTRAST)\n",
        "cope_neg1_1 = -1 * theta_hats_exp + 1 * theta_hats_con\n",
        "t_neg1_1 = cope_neg1_1/np.std(cope_neg1_1)"
      ],
      "id": "Sa-rlsUx7TvB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6fyt1fC_7lB"
      },
      "outputs": [],
      "source": [
        "# PLOT T-CONTRASTS WEIGHTS ON BRAIN\n",
        "\n",
        "filename = \"Q1-Q6_R440.L.inflated.32k_fs_LR.surf.gii\"\n",
        "pathf = os.path.join(DATA_DIR, fname_ex, \"surf\", filename)\n",
        "\n",
        "# EXP > CON\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(t_1_neg1[1, :], cifti_con,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "K6fyt1fC_7lB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myyMUOl8Koj2"
      },
      "outputs": [],
      "source": [
        "# CON > EXP\n",
        "plotting.view_surf(surf_mesh = pathf,\n",
        "                   surf_map = surf_data_from_cifti(t_neg1_1[1, :], cifti_con,'LEFT'),\n",
        "                   cmap = 'hsv', threshold = .0001)"
      ],
      "id": "myyMUOl8Koj2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrZr6ZM7AWJc"
      },
      "source": [
        "# SVM (right now for EXP)"
      ],
      "id": "GrZr6ZM7AWJc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oNDhaCt2AZdI"
      },
      "outputs": [],
      "source": [
        "# Dimensionality reduction on time series (reduce # of voxels to avoid overfitting)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Initializes PCA\n",
        "pca_model = PCA(n_components = 2)\n",
        "\n",
        "# Performs PCA\n",
        "pca_model.fit(time_series_exp)\n",
        "\n",
        "# get PCA scores\n",
        "time_scores_exp = pca_model.transform(time_series_exp)\n",
        "\n",
        "# check shape\n",
        "time_scores_exp.shape"
      ],
      "id": "oNDhaCt2AZdI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GaIJwQZkAxd2"
      },
      "outputs": [],
      "source": [
        "# plot PCA of timepoints\n",
        "\n",
        "plt.figure()\n",
        "cmap = plt.cm.get_cmap('hsv')\n",
        "plt.scatter(x=time_scores_exp[:, 0], y=time_scores_exp[:, 1], c=stim_area_exp_int, cmap=cmap)\n",
        "plt.xlabel('Component 1')\n",
        "plt.ylabel('Component 2')\n",
        "plt.colorbar(ticks=np.arange(0, np.max(stim_area_exp_int) + 1, 100))\n",
        "plt.clim(-0.5, np.max(stim_area_exp_int) + 1)"
      ],
      "id": "GaIJwQZkAxd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C11VN9_BBGcT"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and test data:\n",
        "X = time_scores_exp\n",
        "Y = stim_area_exp_int\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = .2 , random_state = 209) # random state depend on how the data looks like (we might need to shuffle it)\n",
        "\n",
        "# Implement SVM:\n",
        "SVM_classifier = svm.SVC(kernel='rbf') # Type of Kernel can be changed later 'rbf' is a good other option\n",
        "\n",
        "# train the model\n",
        "SVM_classifier.fit(X_train,Y_train)\n",
        "\n",
        "# predict the response:\n",
        "predictions = SVM_classifier.predict(X_test)"
      ],
      "id": "C11VN9_BBGcT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u4Fbp4e3BNw2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Evaluation of the model:\n",
        "\n",
        "print(metrics.classification_report(Y_test, predictions))\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, predictions)\n",
        "# print(confusion_matrix)\n",
        "\n",
        "# plot conf mat\n",
        "ConfusionMatrixDisplay.from_predictions(Y_test, predictions)"
      ],
      "id": "u4Fbp4e3BNw2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX7xRbHnCat-"
      },
      "source": [
        "How many PCs are needed for SVM?"
      ],
      "id": "wX7xRbHnCat-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "6aujtbnoCZmT"
      },
      "outputs": [],
      "source": [],
      "id": "6aujtbnoCZmT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fG-rgg8ECqzJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate the accuracy of EXP SVM using top n components\n",
        "\n",
        "np.random.seed(2022)\n",
        "\n",
        "n = np.arange(1, 21) # 8 min runtime\n",
        "accuracy = []\n",
        "\n",
        "for i in n:\n",
        "  print(\"running simulation for \", str(i), \"components\")\n",
        "  acc = run_svm_sims(i)\n",
        "  accuracy.append(acc)"
      ],
      "id": "fG-rgg8ECqzJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xxeLohxHCoWt"
      },
      "outputs": [],
      "source": [
        "# Visualize evaluations\n",
        "plt.plot(n, accuracy, 'ko')\n",
        "plt.ylim([0, 1])"
      ],
      "id": "xxeLohxHCoWt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rYVcEigHq_2"
      },
      "source": [
        "# Basic CNN"
      ],
      "id": "2rYVcEigHq_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E32XFw_fHq_2"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import matplotlib as mpl"
      ],
      "id": "E32XFw_fHq_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "vFIqS7R6Hq_2"
      },
      "outputs": [],
      "source": [
        "# @title define convolutional layer\n",
        "\n",
        "class ConvolutionalLayer(nn.Module):\n",
        "  \"\"\"Deep network with one convolutional layer\n",
        "     Attributes: conv (nn.Conv2d): convolutional layer\n",
        "  \"\"\"\n",
        "  def __init__(self, c_in=3, c_out=6, K=7, filters=None):\n",
        "    \"\"\"Initialize layer\n",
        "\n",
        "    Args:\n",
        "        c_in: number of input stimulus channels\n",
        "        c_out: number of output convolutional channels\n",
        "        K: size of each convolutional filter\n",
        "        filters: (optional) initialize the convolutional weights\n",
        "\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(c_in, c_out, kernel_size=K,\n",
        "                          padding=K//2, stride=1)\n",
        "    if filters is not None:\n",
        "      self.conv.weight = nn.Parameter(filters)\n",
        "      self.conv.bias = nn.Parameter(torch.zeros((c_out,), dtype=torch.float32))\n",
        "\n",
        "  def forward(self, s):\n",
        "    \"\"\"Run stimulus through convolutional layer\n",
        "\n",
        "    Args:\n",
        "        s (torch.Tensor): n_stimuli x c_in x h x w tensor with stimuli\n",
        "\n",
        "    Returns:\n",
        "        (torch.Tensor): n_stimuli x c_out x h x w tensor with convolutional layer unit activations.\n",
        "\n",
        "    \"\"\"\n",
        "    a = self.conv(s)  # output of convolutional layer\n",
        "\n",
        "    return a"
      ],
      "id": "vFIqS7R6Hq_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "v8PRY2tUHq_2"
      },
      "outputs": [],
      "source": [
        "# @title Helper function: define filters\n",
        "\n",
        "def filters(out_channels=6, K=7):\n",
        "  \"\"\" make example filters, some center-surround and gabors\n",
        "  Returns:\n",
        "      filters: out_channels x K x K\n",
        "  \"\"\"\n",
        "  grid = np.linspace(-K/2, K/2, K).astype(np.float32)\n",
        "  xx,yy = np.meshgrid(grid, grid, indexing='ij')\n",
        "\n",
        "  # create center-surround filters\n",
        "  sigma = 1.1\n",
        "  gaussian = np.exp(-(xx**2 + yy**2)**0.5/(2*sigma**2))\n",
        "  wide_gaussian = np.exp(-(xx**2 + yy**2)**0.5/(2*(sigma*2)**2))\n",
        "  center_surround = gaussian - 0.5 * wide_gaussian\n",
        "\n",
        "  # create gabor filters\n",
        "  thetas = np.linspace(0, 180, out_channels-2+1)[:-1] * np.pi/180\n",
        "  gabors = np.zeros((len(thetas), K, K), np.float32)\n",
        "  lam = 10\n",
        "  phi = np.pi/2\n",
        "  gaussian = np.exp(-(xx**2 + yy**2)**0.5/(2*(sigma*0.4)**2))\n",
        "  for i,theta in enumerate(thetas):\n",
        "    x = xx*np.cos(theta) + yy*np.sin(theta)\n",
        "    gabors[i] = gaussian * np.cos(2*np.pi*x/lam + phi)\n",
        "\n",
        "  filters = np.concatenate((center_surround[np.newaxis,:,:],\n",
        "                            -1*center_surround[np.newaxis,:,:],\n",
        "                            gabors),\n",
        "                           axis=0)\n",
        "  filters /= np.abs(filters).max(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
        "  filters -= filters.mean(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
        "  # convert to torch\n",
        "  filters = torch.from_numpy(filters)\n",
        "  # add channel axis\n",
        "  filters = filters.unsqueeze(1)\n",
        "\n",
        "  return filters"
      ],
      "id": "v8PRY2tUHq_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7i3FdYhRHq_2"
      },
      "outputs": [],
      "source": [
        "# Create and visualize filters\n",
        "\n",
        "example_filters = filters(out_channels=6, K=7)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(example_filters[0,0], vmin=-1, vmax=1, cmap='bwr')\n",
        "plt.title('center-surround filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(example_filters[4,0], vmin=-1, vmax=1, cmap='bwr')\n",
        "plt.title('gabor filter')\n",
        "plt.axis('off');"
      ],
      "id": "7i3FdYhRHq_2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dL5z8MeHq_2"
      },
      "source": [
        "Run convolutional layer on stimulus"
      ],
      "id": "-dL5z8MeHq_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FRvhYLOXHq_3"
      },
      "outputs": [],
      "source": [
        "stim_exp_sum = np.sum(stim_exp, axis = 3)\n",
        "stim_exp_sum.shape"
      ],
      "id": "FRvhYLOXHq_3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xAlsJPIbHq_3"
      },
      "outputs": [],
      "source": [
        "# Stimulus parameters\n",
        "\n",
        "in_channels = 1 # how many input channels in our images\n",
        "h = stim_exp.shape[1] # height of images\n",
        "w = stim_exp.shape[2] # width of images\n",
        "\n",
        "# Convolution layer parameters\n",
        "K = 7 # filter size\n",
        "out_channels = 6 # how many convolutional channels to have in our layer\n",
        "example_filters = filters(out_channels, K) # create filters to use\n",
        "\n",
        "convout = np.zeros(0) # assign convolutional activations to convout\n",
        "\n",
        "# Initialize conv layer and add weights from function filters\n",
        "# you need to specify :\n",
        "# * the number of input channels c_in\n",
        "# * the number of output channels c_out\n",
        "# * the filter size K\n",
        "convLayer = ConvolutionalLayer(c_in = in_channels,\n",
        "                               c_out = out_channels,\n",
        "                               K = K,\n",
        "                               filters = example_filters)\n",
        "\n",
        "# run convLayer on stimulus\n",
        "stimuli_exp = torch.zeros((len(stim_area_exp_int), in_channels, h, w), dtype = torch.float32)\n",
        "\n",
        "## 3 channels?\n",
        "# for i in range(len(stim_area_exp_int)):\n",
        "#\n",
        "#  for c in range(in_channels):\n",
        "#\n",
        "#    stimuli_exp[i, c] = torch.tensor(stim_exp[i, :, :, c], dtype = torch.float32)\n",
        "\n",
        "## 1 channel (sum of 3 channels)\n",
        "for i in range(len(stim_area_exp_int)):\n",
        "\n",
        "  a = stim_exp_sum[i, :, :]\n",
        "  a = np.vstack(a).astype(float)\n",
        "  stimuli_exp[i, 0] = torch.tensor(torch.from_numpy(a), dtype = torch.float32)\n",
        "\n",
        "convout = convLayer(stimuli_exp).detach() # detach gradients"
      ],
      "id": "xAlsJPIbHq_3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "jeWdo_QSNO5Y"
      },
      "outputs": [],
      "source": [
        "# @title plot activations\n",
        "\n",
        "def show_stimulus(img, ax=None):\n",
        "  \"\"\"Visualize a stimulus\"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  ax.imshow(img, cmap=mpl.cm.binary)\n",
        "  ax.set_aspect('auto')\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  ax.spines['left'].set_visible(False)\n",
        "  ax.spines['bottom'].set_visible(False)\n",
        "\n",
        "def plot_example_activations(stimuli, act, channels=[0]):\n",
        "  \"\"\" plot activations act and corresponding stimulus\n",
        "  Args:\n",
        "        stimuli: stimulus input to convolutional layer (n x h x w) or (h x w)\n",
        "        act: activations of convolutional layer (n_bins x conv_channels x n_bins)\n",
        "        channels: which conv channels to plot\n",
        "  \"\"\"\n",
        "  if stimuli.ndim>2:\n",
        "    n_stimuli = stimuli.shape[0]\n",
        "  else:\n",
        "    stimuli = stimuli.unsqueeze(0)\n",
        "    n_stimuli = 1\n",
        "\n",
        "  fig, axs = plt.subplots(n_stimuli,1+len(channels),figsize=(12,12))\n",
        "\n",
        "  # plot stimulus\n",
        "  for i in range(n_stimuli):\n",
        "    show_stimulus(stimuli[i].squeeze(), ax=axs[i, 0])\n",
        "    axs[i, 0].set_title('stimulus')\n",
        "\n",
        "    # plot example activations\n",
        "    for k, (channel, ax) in enumerate(zip(channels, axs[i][1:])):\n",
        "      img=ax.imshow(act[i,channel], vmin=-3, vmax=3, cmap='bwr')\n",
        "      ax.set_xlabel('x-pos')\n",
        "      ax.set_ylabel('y-pos')\n",
        "      ax.set_title('channel %d'%channel)\n",
        "  ax = fig.add_axes([1.05,0.8,0.01,0.1])\n",
        "  plt.colorbar(img, cax=ax)\n",
        "  ax.set_title('activation\\n strength')"
      ],
      "id": "jeWdo_QSNO5Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vTYUKG-VHq_3"
      },
      "outputs": [],
      "source": [
        "plot_example_activations(stimuli_exp[40:46, :, :, :], convout[40:46, :, :, :], channels=np.arange(0, out_channels))"
      ],
      "id": "vTYUKG-VHq_3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqTapEI31Tdn"
      },
      "source": [
        "# Normative encoding model"
      ],
      "id": "bqTapEI31Tdn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "bTx_kgvb1Xba"
      },
      "outputs": [],
      "source": [
        "# @title Helper functions\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  \"\"\"Deep convolutional network with one convolutional + pooling layer followed\n",
        "  by one fully connected layer\n",
        "\n",
        "  Args:\n",
        "    h_in (int): height of input image, in pixels (i.e. number of rows)\n",
        "    w_in (int): width of input image, in pixels (i.e. number of columns)\n",
        "\n",
        "  Attributes:\n",
        "    conv (nn.Conv2d): filter weights of convolutional layer\n",
        "    pool (nn.MaxPool2d): max pooling layer\n",
        "    dims (tuple of ints): dimensions of output from pool layer\n",
        "    fc (nn.Linear): weights and biases of fully connected layer\n",
        "    out (nn.Linear): weights and biases of output layer\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, h_in, w_in):\n",
        "    super().__init__()\n",
        "    C_in = 1  # input stimuli have only 1 input channel\n",
        "    C_out = 6  # number of output channels (i.e. of convolutional kernels to convolve the input with)\n",
        "    K = 7  # size of each convolutional kernel\n",
        "    Kpool = 8  # size of patches over which to pool\n",
        "    self.conv = nn.Conv2d(C_in, C_out, kernel_size=K, padding=K//2)  # add padding to ensure that each channel has same dimensionality as input\n",
        "    self.pool = nn.MaxPool2d(Kpool)\n",
        "    self.dims = (C_out, h_in // Kpool, w_in // Kpool)  # dimensions of pool layer output\n",
        "    self.fc = nn.Linear(np.prod(self.dims), 10)  # flattened pool output --> 10D representation\n",
        "    self.out = nn.Linear(10, 1)  # 10D representation --> scalar\n",
        "    self.conv.weight = nn.Parameter(filters(C_out, K))\n",
        "    self.conv.bias = nn.Parameter(torch.zeros((C_out,), dtype=torch.float32))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Classify grating stimulus as tilted right or left\n",
        "\n",
        "    Args:\n",
        "      x (torch.Tensor): p x 48 x 64 tensor with pixel grayscale values for\n",
        "          each of p stimulus images.\n",
        "\n",
        "    Returns:\n",
        "      torch.Tensor: p x 1 tensor with network outputs for each input provided\n",
        "          in x. Each output should be interpreted as the probability of the\n",
        "          corresponding stimulus being tilted right.\n",
        "\n",
        "    \"\"\"\n",
        "    x = x.unsqueeze(1)  # p x 1 x 48 x 64, add a singleton dimension for the single stimulus channel\n",
        "    x = torch.relu(self.conv(x))  # output of convolutional layer\n",
        "    x = self.pool(x)  # output of pooling layer\n",
        "    x = x.view(-1, np.prod(self.dims))  # flatten pooling layer outputs into a vector\n",
        "    x = torch.relu(self.fc(x))  # output of fully connected layer\n",
        "    x = torch.sigmoid(self.out(x))  # network output\n",
        "    return x\n",
        "\n",
        "\n",
        "def train(net, train_data, train_labels,\n",
        "          n_epochs=25, learning_rate=0.0005,\n",
        "          batch_size=100, momentum=.99):\n",
        "  \"\"\"Run stochastic gradient descent on binary cross-entropy loss for a given\n",
        "  deep network (cf. appendix for details)\n",
        "\n",
        "  Args:\n",
        "    net (nn.Module): deep network whose parameters to optimize with SGD\n",
        "    train_data (torch.Tensor): n_train x h x w tensor with stimulus gratings\n",
        "    train_labels (torch.Tensor): n_train x 1 tensor with true tilt of each\n",
        "      stimulus grating in train_data, i.e. 1. for right, 0. for left\n",
        "    n_epochs (int): number of times to run SGD through whole training data set\n",
        "    batch_size (int): number of training data samples in each mini-batch\n",
        "    learning_rate (float): learning rate to use for SGD updates\n",
        "    momentum (float): momentum parameter for SGD updates\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize binary cross-entropy loss function\n",
        "  loss_fn = nn.BCELoss()\n",
        "\n",
        "  # Initialize SGD optimizer with momentum\n",
        "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "  # Placeholder to save loss at each iteration\n",
        "  track_loss = []\n",
        "\n",
        "  # Loop over epochs\n",
        "  for i in range(n_epochs):\n",
        "\n",
        "    # Split up training data into random non-overlapping mini-batches\n",
        "    ishuffle = torch.randperm(train_data.shape[0])  # random ordering of training data\n",
        "    minibatch_data = torch.split(train_data[ishuffle], batch_size)  # split train_data into minibatches\n",
        "    minibatch_labels = torch.split(train_labels[ishuffle], batch_size)  # split train_labels into minibatches\n",
        "\n",
        "    # Loop over mini-batches\n",
        "    for stimuli, tilt in zip(minibatch_data, minibatch_labels):\n",
        "\n",
        "      # Evaluate loss and update network weights\n",
        "      out = net(stimuli)  # predicted probability of tilt right\n",
        "      loss = loss_fn(out, tilt)  # evaluate loss\n",
        "      optimizer.zero_grad()  # clear gradients\n",
        "      loss.backward()  # compute gradients\n",
        "      optimizer.step()  # update weights\n",
        "\n",
        "      # Keep track of loss at each iteration\n",
        "      track_loss.append(loss.item())\n",
        "\n",
        "    # Track progress\n",
        "    if (i + 1) % (n_epochs // 5) == 0:\n",
        "      print(f'epoch {i + 1} | loss on last mini-batch: {loss.item(): .2e}')\n",
        "\n",
        "  print('training done!')\n",
        "\n",
        "\n",
        "def get_hidden_activity(net, stimuli, layer_labels):\n",
        "  \"\"\"Retrieve internal representations of network\n",
        "\n",
        "  Args:\n",
        "    net (nn.Module): deep network\n",
        "    stimuli (torch.Tensor): p x 48 x 64 tensor with stimuli for which to\n",
        "      compute and retrieve internal representations\n",
        "    layer_labels (list): list of strings with labels of each layer for which\n",
        "      to return its internal representations\n",
        "\n",
        "  Returns:\n",
        "    dict: internal representations at each layer of the network, in\n",
        "      numpy arrays. The keys of this dict are the strings in layer_labels.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Placeholder\n",
        "  hidden_activity = {}\n",
        "\n",
        "  # Attach 'hooks' to each layer of the network to store hidden\n",
        "  # representations in hidden_activity\n",
        "  def hook(module, input, output):\n",
        "    module_label = list(net._modules.keys())[np.argwhere([module == m for m in net._modules.values()])[0, 0]]\n",
        "    if module_label in layer_labels:  # ignore output layer\n",
        "      hidden_activity[module_label] = output.view(stimuli.shape[0], -1).detach().numpy()\n",
        "  hooks = [layer.register_forward_hook(hook) for layer in net.children()]\n",
        "\n",
        "  # Run stimuli through the network\n",
        "  pred = net(stimuli)\n",
        "\n",
        "  # Remove the hooks\n",
        "  [h.remove() for h in hooks]\n",
        "\n",
        "  return hidden_activity"
      ],
      "id": "bTx_kgvb1Xba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "YEUXrDAg6foc"
      },
      "outputs": [],
      "source": [
        "# @title Plotting functions\n",
        "\n",
        "def plot_corr_matrix(rdm, ax=None):\n",
        "  \"\"\"Plot dissimilarity matrix\n",
        "\n",
        "  Args:\n",
        "    rdm (numpy array): n_stimuli x n_stimuli representational dissimilarity\n",
        "      matrix\n",
        "    ax (matplotlib axes): axes onto which to plot\n",
        "\n",
        "  Returns:\n",
        "    nothing\n",
        "\n",
        "  \"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  image = ax.imshow(rdm, vmin=0.0, vmax=2.0)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  cbar = plt.colorbar(image, ax=ax, label='dissimilarity')\n",
        "\n",
        "\n",
        "def plot_multiple_rdm(rdm_dict):\n",
        "  \"\"\"Draw multiple subplots for each RDM in rdm_dict.\"\"\"\n",
        "  fig, axs = plt.subplots(1, len(rdm_dict),\n",
        "                          figsize=(4 * len(resp_dict), 3.5))\n",
        "\n",
        "  # Compute RDM's for each set of responses and plot\n",
        "  for i, (label, rdm) in enumerate(rdm_dict.items()):\n",
        "\n",
        "    image = plot_corr_matrix(rdm, axs[i])\n",
        "    axs[i].set_title(label)\n",
        "\n",
        "\n",
        "def plot_rdm_rdm_correlations(rdm_sim):\n",
        "  \"\"\"Draw a bar plot showing between-RDM correlations.\"\"\"\n",
        "  f, ax = plt.subplots()\n",
        "  ax.bar(rdm_sim.keys(), rdm_sim.values())\n",
        "  ax.set_xlabel('Deep network model layer')\n",
        "  ax.set_ylabel('Correlation of model layer RDM\\nwith mouse V1 RDM')\n",
        "\n",
        "\n",
        "def plot_rdm_rows(ori_list, rdm_dict, rdm_oris):\n",
        "  \"\"\"Plot the dissimilarity of response to each stimulus with response to one\n",
        "  specific stimulus\n",
        "\n",
        "  Args:\n",
        "    ori_list (list of float): plot dissimilarity with response to stimulus with\n",
        "      orientations closest to each value in this list\n",
        "    rdm_dict (dict): RDM's from which to extract dissimilarities\n",
        "    rdm_oris (np.ndarray): orientations corresponding to each row/column of RDMs\n",
        "    in rdm_dict\n",
        "\n",
        "  \"\"\"\n",
        "  n_col = len(ori_list)\n",
        "  f, axs = plt.subplots(1, n_col, figsize=(4 * n_col, 4), sharey=True)\n",
        "\n",
        "  # Get index of orientation closest to ori_plot\n",
        "  for ax, ori_plot in zip(axs, ori_list):\n",
        "    iori = np.argmin(np.abs(rdm_oris - ori_plot))\n",
        "\n",
        "    # Plot dissimilarity curves in each RDM\n",
        "    for label, rdm in rdm_dict.items():\n",
        "      ax.plot(rdm_oris, rdm[iori, :], label=label)\n",
        "\n",
        "    # Draw vertical line at stimulus we are plotting dissimilarity w.r.t.\n",
        "    ax.axvline(rdm_oris[iori], color=\".7\", zorder=-1)\n",
        "\n",
        "    # Label axes\n",
        "    ax.set_title(f'Dissimilarity with response\\nto {ori_plot: .0f}$^o$ stimulus')\n",
        "    ax.set_xlabel('Stimulus orientation ($^o$)')\n",
        "\n",
        "  axs[0].set_ylabel('Dissimilarity')\n",
        "  axs[-1].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))"
      ],
      "id": "YEUXrDAg6foc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpCJf_RV2FQA"
      },
      "outputs": [],
      "source": [
        "# Stimulus parameters\n",
        "\n",
        "in_channels = 1 # how many input channels in our images\n",
        "h = stim_exp.shape[1] # height of images\n",
        "w = stim_exp.shape[2] # width of images\n",
        "\n",
        "# Convolution layer parameters\n",
        "K = 7 # filter size\n",
        "out_channels = 6 # how many convolutional channels to have in our layer\n",
        "example_filters = filters(out_channels, K) # create filters to use\n",
        "\n",
        "# run convLayer on stimulus\n",
        "stimuli_exp = torch.zeros((len(stim_area_exp_int), h, w), dtype = torch.float32)\n",
        "\n",
        "## 1 channel (sum of 3 channels)\n",
        "for i in range(len(stim_area_exp_int)):\n",
        "\n",
        "  a = stim_exp_sum[i, :, :]\n",
        "  a = np.vstack(a).astype(float)\n",
        "  stimuli_exp[i] = torch.tensor(torch.from_numpy(a), dtype = torch.float32)"
      ],
      "id": "cpCJf_RV2FQA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QndE7jNi1pWn"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(2022)\n",
        "torch.manual_seed(2022)\n",
        "\n",
        "# Initialize CNN model\n",
        "net = CNN(h, w)\n",
        "\n",
        "# stimulus area\n",
        "area_exp = torch.tensor(stim_area_exp).type(torch.float).unsqueeze(-1)\n",
        "\n",
        "# Train model\n",
        "train(net, stimuli_exp, area_exp)"
      ],
      "id": "QndE7jNi1pWn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I50m1Yua3cNW"
      },
      "outputs": [],
      "source": [
        "# extract model internal representations of each stimulus in the V1 data\n",
        "layer_labels = ['pool', 'fc']\n",
        "exp_model = get_hidden_activity(net, stimuli_exp, layer_labels)"
      ],
      "id": "I50m1Yua3cNW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "86NsibXq5CHD"
      },
      "outputs": [],
      "source": [
        "print(exp_model['pool'].shape, exp_model['fc'].shape)"
      ],
      "id": "86NsibXq5CHD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CSDnMu8A7_wY"
      },
      "outputs": [],
      "source": [
        "## COMPUTE RDMS FOR THE NEURAL SIGNALS AND EACH LAYER\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# z-score responses to each stimulus\n",
        "z_signal_exp = zscore(time_series_exp, axis=1)\n",
        "z_pool_exp = zscore(exp_model['pool'], axis=1)\n",
        "z_fc_exp = zscore(exp_model['fc'], axis=1)\n",
        "\n",
        "# Compute RDM\n",
        "RDM_signal_exp = 1 - (1/z_signal_exp.shape[1]) * (np.matmul(z_signal_exp, z_signal_exp.T))\n",
        "RDM_pool_exp = 1 - (1/z_pool_exp.shape[1]) * (np.matmul(z_pool_exp, z_pool_exp.T))\n",
        "RDM_fc_exp = 1 - (1/z_fc_exp.shape[1]) * (np.matmul(z_fc_exp, z_fc_exp.T))"
      ],
      "id": "CSDnMu8A7_wY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6SPov_5z8Fz-"
      },
      "outputs": [],
      "source": [
        "# plot RDMs\n",
        "plt.rcParams['figure.figsize'] = [20, 15]\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "\n",
        "ax1.set_title(\"fMRI voxels\")\n",
        "ax1.imshow(RDM_signal_exp)\n",
        "\n",
        "ax2.set_title(\"Pool layer\")\n",
        "ax2.imshow(RDM_pool_exp)\n",
        "\n",
        "ax3.set_title(\"FC layer\")\n",
        "ax3.imshow(RDM_fc_exp)\n",
        "# cbar = plt.colorbar(fig, ax=ax3, label='dissimilarity')\n",
        "\n",
        "plt.show()"
      ],
      "id": "6SPov_5z8Fz-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p3uBSVQU-ElG"
      },
      "outputs": [],
      "source": [
        "# indices of off-diagonal elements\n",
        "ioffdiag = np.triu_indices(RDM_signal_exp.shape[0], k=1)\n",
        "\n",
        "# correlation of RDM for FC layer\n",
        "RDM_signal_exp_offdiag = RDM_signal_exp[ioffdiag]]\n",
        "RDM_fc_exp_offdiag = RDM_fc_exp[ioffdiag]\n",
        "\n",
        "np.corrcoef(RDM_signal_exp_offdiag, RDM_fc_exp_offdiag)[0,1]"
      ],
      "id": "p3uBSVQU-ElG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZhgnpbrIEme1"
      },
      "outputs": [],
      "source": [
        "# correlation of RDM for pool layer\n",
        "\n",
        "RDM_pool_exp_offdiag = RDM_pool_exp[ioffdiag]\n",
        "\n",
        "# find and remove NAs\n",
        "na_values = np.isnan(RDM_pool_exp_offdiag)\n",
        "\n",
        "RDM_pool_exp_offdiag_nona = RDM_pool_exp_offdiag[~na_values]\n",
        "RDM_signal_exp_offdiag_nona = RDM_signal_exp_offdiag[~na_values]\n",
        "\n",
        "# correlate\n",
        "np.corrcoef(RDM_signal_exp_offdiag_nona, RDM_pool_exp_offdiag_nona)[0,1]"
      ],
      "id": "ZhgnpbrIEme1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qrhWGu8SInKU"
      },
      "outputs": [],
      "source": [
        "z_fc_exp.shape"
      ],
      "id": "qrhWGu8SInKU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4zpSQywxGq-l"
      },
      "outputs": [],
      "source": [
        "# Visualize tuning curves\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20, 5]\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
        "\n",
        "ax1.set_title(\"fMRI response\")\n",
        "voxels = np.random.choice(time_series_exp.shape[1], 3, replace = False)\n",
        "ax1.plot(time_series_exp[:, voxels])\n",
        "\n",
        "ax2.set_title(\"Pool layer respose\")\n",
        "pool_neurons = np.random.choice(exp_model['pool'].shape[1], 3, replace = False)\n",
        "ax2.plot(exp_model['pool'][:, pool_neurons])\n",
        "\n",
        "ax3.set_title(\"FC layer respose\")\n",
        "fc_neurons = np.random.choice(exp_model['fc'].shape[1], 3, replace = False)\n",
        "ax3.plot(exp_model['fc'][:, fc_neurons])\n",
        "\n",
        "plt.show()"
      ],
      "id": "4zpSQywxGq-l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pOqwb0uzGcdu"
      },
      "outputs": [],
      "source": [
        "# Dimensionality reduction of responses"
      ],
      "id": "pOqwb0uzGcdu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wHGGUzqfsb"
      },
      "source": [
        "# SVM for stimulus type"
      ],
      "id": "Y9wHGGUzqfsb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vlHdlvoAqiqS"
      },
      "outputs": [],
      "source": [],
      "id": "vlHdlvoAqiqS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PWN8yh5CqlW6"
      },
      "outputs": [],
      "source": [
        "# Dimensionality reduction on time series (reduce # of voxels to avoid overfitting)\n",
        "\n",
        "# number of components for each feature\n",
        "n_comps = 20\n",
        "\n",
        "# Initializes PCA\n",
        "pca_model = PCA(n_components = n_comps)\n",
        "\n",
        "# Performs PCA\n",
        "pca_model.fit(time_series_stims)\n",
        "\n",
        "# get PCA scores\n",
        "time_scores_stims = pca_model.transform(time_series_stims)\n",
        "\n",
        "# check shape\n",
        "time_scores_stims.shape"
      ],
      "id": "PWN8yh5CqlW6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z0Y5tyhzquyS"
      },
      "outputs": [],
      "source": [
        "X = time_scores_stims\n",
        "Y = stims_on\n",
        "\n",
        "# split\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size = .2) # random state depend on how the data looks like (we might need to shuffle it)\n",
        "# Implement SVM:\n",
        "SVM_classifier_stims = svm.SVC(kernel='rbf', max_iter=1e5, C=1e4) # Type of Kernel can be changed later 'rbf' is a good other option\n",
        "# train the model\n",
        "SVM_classifier_stims.fit(X_train,Y_train)\n",
        "\n",
        "# predict the response:\n",
        "predictions_stims = SVM_classifier_stims.predict(X_test)"
      ],
      "id": "Z0Y5tyhzquyS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0qWqhhcnqwSE"
      },
      "outputs": [],
      "source": [
        "print('accuracy', metrics.accuracy_score(Y_test, predictions_stims))\n",
        "print(metrics.classification_report(Y_test, predictions_stims))\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, predictions_stims)\n",
        "print(confusion_matrix)"
      ],
      "id": "0qWqhhcnqwSE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1aziRuEmnrd"
      },
      "source": [
        "**Stack PCAs of different stimuli:**"
      ],
      "id": "q1aziRuEmnrd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JnwkfEpJvLVC"
      },
      "outputs": [],
      "source": [
        "# Stacking time scores and stimulus features for all the stimuli:\n",
        "# 1 = exp\n",
        "general_time_scores = np.array(time_scores_exp)\n",
        "stim_on_exp = stim_area_exp\n",
        "stim_on_exp[stim_on_exp>0] = 1\n",
        "stims_on = stim_on_exp\n",
        "# 2 = con\n",
        "general_time_scores = np.append(general_time_scores, np.array(time_scores_con), 0)\n",
        "stim_on_con = stim_area_con\n",
        "stim_on_con[stim_on_con>0] = 2\n",
        "stims_on.append(stim_on_con)\n",
        "# 3 = CW\n",
        "general_time_scores = np.append(general_time_scores, np.array(time_scores_cw), 0)\n",
        "stim_on_cw = [np.zeros(22),np.ones(256)*3,np.zeros(22)]\n",
        "stims_on = np.append(stims_on, stim_on_cw)\n",
        "# 4 = BAR1\n",
        "general_time_scores.append(time_scores_bar1)\n",
        "general_time_scores = np.append(general_time_scores, np.array(time_scores_bar1), 0)\n",
        "stim_on_bar1 = bar_direction\n",
        "stim_on_bar1[stim_on_bar1>0] = 4\n",
        "stims_on = np.append(stims_on, stim_on_bar1)\n",
        "# 5 = CCW\n",
        "# 6 = BAR2"
      ],
      "id": "JnwkfEpJvLVC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LDzT-4Z1gyrY"
      },
      "outputs": [],
      "source": [
        "# SVM on the stacked PCAs and stimuli features:\n",
        "\n",
        "# defining X and Y:\n",
        "X = general_time_scores\n",
        "Y = stims_on\n",
        "# split\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size = .2) # random state depend on how the data looks like (we might need to shuffle it)\n",
        "# Implement SVM:\n",
        "SVM_classifier_stims = svm.SVC(kernel='rbf', max_iter=1e5, C=1e4) # Type of Kernel can be changed later 'rbf' is a good other option\n",
        "# train the model\n",
        "SVM_classifier_stims.fit(X_train,Y_train)\n",
        "# predict the response:\n",
        "predictions_stims = SVM_classifier_stims.predict(X_test)"
      ],
      "id": "LDzT-4Z1gyrY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SRONM0lGg2ER"
      },
      "outputs": [],
      "source": [
        "# Evaluation of the model:\n",
        "print('accuracy', metrics.accuracy_score(Y_test, predictions_stims))\n",
        "print(metrics.classification_report(Y_test, predictions_stims))\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, predictions_stims)\n",
        "print(confusion_matrix)"
      ],
      "id": "SRONM0lGg2ER"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}